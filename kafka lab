<<<<<<<<<<<<      LAB 1    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

How to check ZK Leader Follower

BROKER ZOOKEEPER VERIFY >>>

zookeeper-shell node1.server.com:2181 ls /brokers/ids


docker-compose exec tools bash

Create Topic >>>>

kafka-topics --bootstrap-server kafka-1:9092 --create --partitions 1 --replication-factor 1 --topic testing

PRODUCE >>>

kafka-console-producer --broker-list kafka-1:9092 --topic testing

kafka-console-producer --broker-list kafka-1:9092 --topic testing --property parse.key=true --property key.separator=,

1,my first record
2,second record

CONSUME >>>

kafka-console-consumer --bootstrap-server kafka-1:9092 --from-beginning --topic testing

kafka-console-consumer --bootstrap-server kafka-1:9092 --from-beginning --topic testing --property print.key=true

<<<<<<<<<<<<      LAB 2    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

a. Investigating the Distributed Log

kafka-topics \
--create \
--bootstrap-server kafka-1:9092 \
--topic replicated-topic \
--partitions 6 \
--replication-factor 2

kafka-topics \
--describe \
--bootstrap-server kafka-1:9092 \
--topic replicated-topic

kafka-console-producer \
--broker-list kafka-1:9092,kafka-2:9092,kafka-3:9092 \
--topic replicated-topic

kafka-producer-perf-test \
--topic replicated-topic \
--num-records 6000 \
--record-size 100 \
--throughput 1000 \
--producer-props bootstrap.servers=kafka-1:9092,kafka-2:9092,kafka-3:9092

kafka-console-producer \
--broker-list kafka-1:9092,kafka-2:9092,kafka-3:9092 \
--topic replicated-topic

cat /var/lib/kafka/data/recovery-point-offset-checkpoint | grep replicated-topic

cat /var/lib/kafka/data/replication-offset-checkpoint | grep replicated-topic

docker-compose exec kafka-1 /bin/bash

cat /var/lib/kafka/data/replicated-topic-0/leaderepoch-checkpoint

0   >>>>>>>>>>> message format
1   >>>>>>>>>>> no of leaders
1 0
2 54 >>>>>>>>>>>  epoch id with offset

kafka-dump-log --print-data-log --files /var/lib/kafka/data/replicated-topic-
0/00000000000000000000.log

kafka-run-class kafka.tools.DumpLogSegments \
--files /var/lib/kafka/data/replicated-topic-
0/00000000000000000000.index

(Set Trigger) Under Replicated and Test it with Failover

zookeeper-shell zk-1:2181 get /controller
docker-compose stop kafka-1
docker-compose ps
zookeeper-shell zk-1:2181 ls /brokers/ids
docker-compose logs kafka-1 | tail
docker-compose logs kafka-1 | grep Resigned

kafka-console-producer \
--broker-list kafka-2:9092,kafka-3:9092 \
--topic replicated-topic

docker-compose exec kafka-3 \
cat /var/lib/kafka/data/replicated-topic-0/leader-epochcheckpoint

docker-compose start kafka-1



<<<<<<<<<<<<<<<<<<<<< Lab 04 Managing a Kafka Cluster >>>>>>>>>>>>>>>>>>>>>>>>>


a. Exploring Configuration

Explore All the Configuration in Control Center


b. Automating Kafka Configuration

Ansible deployment


c. Increasing Replication Factor

kafka-topics \
--bootstrap-server kafka-1:9092,kafka-2:9092,kafka-3:9092 \
--create \
--topic test \
--partitions 3 \
--replication-factor 3

kafka-topics \
--bootstrap-server kafka-1:9092,kafka-2:9092,kafka-3:9092 \
--describe \
--topic test

cat << EOF > replicate_topic_test_plan.json
{"version":1,
"partitions":[
{"topic":"test","partition":0,"replicas":[101,102,103]},
{"topic":"test","partition":1,"replicas":[101,102,103]},
{"topic":"test","partition":2,"replicas":[102,103.101]}]
}
EOF

cat << EOF > replicate_topic_test_plan.json
{"version":1,
"partitions":[
{"topic":"test","partition":0,"replicas":[101]},
{"topic":"test","partition":1,"replicas":[102]},
{"topic":"test","partition":2,"replicas":[103]}]
}
EOF

kafka-reassign-partitions \
--zookeeper zk-1:2181,zk-2:9092,zk-3:9092 \
--reassignment-json-file replicate_topic_test_plan.json \
--execute

d. Kafka Administrative Tools

(delete)

kafka-configs \
--zookeeper zk-1:2181 \
--alter \
--entity-type topics \
--entity-name my_topic \
--add-config retention.ms=0

(compaction)

kafka-topics --create --zookeeper zk-1:2181 --topic latest-product-price --replication-factor 1 --partitions 1 --config "cleanup.policy=compact" --config "delete.retention.ms=100"  --config "segment.ms=100" --config "min.cleanable.dirty.ratio=0.01"

kafka-console-producer --broker-list kafka-1:9092 --topic latest-product-price --property parse.key=true --property key.separator=:
>p3:10$
>p5:7$
>p3:11$
>p6:25$
>p6:12$
>p5:14$
>p5:17$

kafka-console-consumer --bootstrap-server kafka-1:9092 --topic latest-product-price --property  print.key=true --property key.separator=: --from-beginning
p3:11$
p6:12$
p5:14$
p5:17$

kafka-topics --bootstrap-server kafka-1:9092 \
--create --topic i-love-kafka \
--partitions 5 --replication-factor 3 \
--config min.insync.replicas=2 cleanup.policy=delete

kafka-topics --bootstrap-server kafka-1:9092 \
--create --topic i-love-kafka \
--partitions 5 --replication-factor 3 \
--config min.insync.replicas=2 cleanup.policy=compact

kafka-topics \
--bootstrap-server kafka-1:9092 \
--delete \
--topic replicated-topic

(Rebalance)
kafka-topics \
--bootstrap-server kafka-1:9092 \
--create \
--topic moving \
--replica-assignment \
101:102,102:101,101:102,102:101,101:102,102:101

kafka-producer-perf-test \
--topic moving1 \
--num-records 2000000 \
--record-size 1000 \
--throughput 1000000000 \
--producer-props bootstrap.servers=kafka-1:9092,kafka-2:9092

kafka-consumer-perf-test \
--broker-list kafka-1:9092,kafka-2:9092 \
--topic moving1 \
--group test-group \
--threads 1 \
--show-detailed-stats \
--timeout 1000000 \
--reporting-interval 5000 \
--messages 10000000


confluent-rebalancer execute \
--zookeeper zk-1:2181 \
--metrics-bootstrap-server kafka-1:9092,kafka-2:9092 \
--throttle 1000000 \
--verbose \
--force

kafka-configs \
--zookeeper zk-1:2181 \
--describe \
--entity-type brokers

kafka-configs \
--zookeeper zk-1:2181 \
--describe \
--entity-type topics | grep -E "throttled\.replicas=[^,]+"

confluent-rebalancer status \
--zookeeper zk-1:2181
Partitions being rebalanced:
Topic moving: 0,1,3,5

confluent-rebalancer execute \
--zookeeper zk-1:2181 \
--metrics-bootstrap-server kafka-1:9092,kafka-2:9092 \
--throttle 1000000000 \
--verbose

kafka-configs \
--describe \
--zookeeper zk-1:2181 \
--entity-type brokers

confluent-rebalancer status \
--zookeeper zk-1:2181

kafka-configs \
--describe \
--zookeeper zk-1:2181 \
--entity-type brokers

(OPEN SOURCE Rebalancer)

cd ~/confluent-admin/data

echo '{"topics": [{"topic": "moving1"}],"version":1}' > topics-tomove.json

kafka-reassign-partitions \
--zookeeper zk-1:2181 \
--topics-to-move-json-file topics-to-move.json \
--broker-list "101,102,103" \
--generate > reassignment.json

cat reassignment.json
Remove Current Partition Plan

kafka-configs \
--describe \
--zookeeper zk-1:2181 \
--entity-type brokers

kafka-reassign-partitions \
--zookeeper zk-1:2181 \
--reassignment-json-file reassignment.json \
--execute \
--throttle 1000000

kafka-configs \
--describe \
--zookeeper zk-1:2181 \
--entity-type brokers

kafka-reassign-partitions \
--zookeeper zk-1:2181 \
--reassignment-json-file reassignment.json \
--verify

kafka-topics \
--bootstrap-server kafka-1:9092 \
--describe \
--topic moving

kafka-reassign-partitions \
--zookeeper zk-1:2181 \
--reassignment-json-file reassignment.json \
--execute \
--throttle 1000000000

kafka-configs \
--describe \
--zookeeper zk-1:2181 \
--entity-type brokers

kafka-reassign-partitions \
--zookeeper zk-1:2181 \
--reassignment-json-file reassignment.json \
--verify

kafka-configs \
--describe \
--zookeeper zk-1:2181 \
--entity-type brokers



(Failed Broker)

docker-compose exec kafka-1 ls /var/lib/kafka/data

docker-compose stop kafka-1 && \
docker-compose rm kafka-1 && \
docker volume rm confluent-admin_data-kafka-1

docker-compose up -d

docker-compose exec kafka-1 ls /var/lib/kafka/data


<<<<<<<<<<<<<<<< Lab 05 Optimizing Kafka’ Performance  >>>>>>>>>>>>>>>>>>>

a. Exploring Producer Performance

kafka-producer-perf-test \
--topic performance \
--num-records 1000000 \
--record-size 100 \
--throughput 1000000 \
--producer-props \
bootstrap.servers=kafka-1:9092,kafka-2:9092 \
acks=1

Test with Different Batch Size and Linger MS

kafka-producer-perf-test \
--topic performance \
--num-records 1000000 \
--record-size 100 \
--throughput 10000000 \
--producer-props \
bootstrap.servers=kafka-1:9092,kafka-2:9092 \
acks=all \
batch.size=400000 \
linger.ms=500

b. Modifying Partitions and Viewing Offsets

kafka-topics \
--bootstrap-server kafka-1:9092 \
--create \
--topic grow-topic \
--partitions 6 \
--replication-factor 3

kafka-console-producer \
--broker-list kafka-1:9092,kafka-2:9092 \
--topic grow-topic
> KSQL
> Streaming
> Engine
<Ctrl-d>

kafka-console-consumer \
--consumer-property group.id=test-consumer-group \
--from-beginning \
--topic grow-topic \
--bootstrap-server kafka-1:9092,kafka-2:9092

kafka-consumer-groups \
--bootstrap-server kafka-1:9092,kafka-2:9092 \
--group test-consumer-group \
--describe

kafka-topics \
--bootstrap-server kafka-1:9092 \
--alter \
--topic grow-topic \
--partitions 12

kafka-consumer-groups \
--bootstrap-server kafka-1:9092,kafka-2:9092 \
--group test-consumer-group \
--describe

(Kafka-based Offset Storage)

kafka-console-producer \
--broker-list kafka-1:9092,kafka-2:9092 \
--topic new-topic

kafka-console-consumer \
--topic __consumer_offsets \
--bootstrap-server kafka-1:9092,kafka-2:9092 \
--formatter
"kafka.coordinator.group.GroupMetadataManager $OffsetsMessageFormatter" \
| grep performance

kafka-console-consumer \
--from-beginning \
--topic new-topic \
--group new-group \
--bootstrap-server kafka-1:9092,kafka-2:9092

c. Performance Tuning

Check for the Request Latency Percentile
Observe that most of the fetch request time is in Response remote time waiting for the
replica.fetch.wait.max.ms timeout. When Producers are not writing records, the
fetch request latency will go up to replica.fetch.wait.max.ms (default 500ms).

kafka-topics \
--bootstrap-server kafka-1:9092 \
--create \
--topic grow-topic \
--partitions 6 \
--replication-factor 3

kafka-producer-perf-test \
--topic grow-topic \
--num-records 1000000 --record-size 100 --throughput 1000 \
--producer-props bootstrap.servers=kafka-1:9092,kafka-2:9092

(Tune Consumers to Decrease Broker CPU Load)

kafka-topics \
--bootstrap-server kafka-1:9092 \
--create \
--topic i-love-logs \
--partitions 1 \
--replication-factor 1

NS=io.confluent.monitoring.clients.interceptor && \
kafka-producer-perf-test \
--topic i-love-logs \
--num-records 10000000 \
--record-size 100 \
--throughput 1000 \
--producer-props \
bootstrap.servers=kafka-1:9092,kafka-2:9092 \
interceptor.classes=${NS}.MonitoringProducerInterceptor

kafka-consumer-perf-test \
--broker-list kafka-1:9092,kafka-2:9092 \
--topic i-love-logs \
--group cg \
--messages 10000000 \
--threads 1 \
--show-detailed-stats \
--reporting-interval 5000

docker-compose exec kafka-1 top -n10

echo "fetch.min.bytes=100000" > data/consumer.properties

kafka-consumer-perf-test \
--broker-list kafka-1:9092,kafka-2:9092 \
--topic i-love-logs \
--group cg-fetch-min \
--messages 10000000 \
--threads 1 \
--show-detailed-stats \
--reporting-interval 5000 \
--consumer.config data/consumer.properties

docker-compose exec kafka-1 top -n10


(Simulating Over Consumption)

kafka-consumer-groups \
--bootstrap-server kafka-1:9092,kafka-2:9092 \
--group cg \
--reset-offsets \
--to-earliest \
--all-topics \
--execute

PACKAGE=io.confluent.monitoring.clients.interceptor && \
echo "interceptor.classes=${PACKAGE}.MonitoringConsumerInterceptor" \
> data/consumer-monitor.properties

kafka-console-consumer \
--bootstrap-server kafka-1:9092 \
--group cg \
--consumer.config /apps/data/consumer-monitor.properties \
--from-beginning \
--topic i-love-logs

CHeck Consumption

Cluster 1 → Consumers → cg → Consumption
